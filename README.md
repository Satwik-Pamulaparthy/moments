# Moments - Photo Sharing Social Networking App

A photo sharing social networking app built with Python and Flask. 

This project implements an image processing application with two key features:

Alternative Text Generation (using machine learning models to generate captions for images).
Image Search (using machine learning models to tag images and search for them based on keywords).
Demo: http://moments.helloflask.com



## ![Screenshot 2025-02-16 224150](https://github.com/user-attachments/assets/305f6025-05a5-446e-b225-7df70dda11a8)


Clone the repo:

```
$ git clone https://github.com/greyli/moments
$ cd moments
```

Install dependencies with [PDM](https://pdm.fming.dev):

```
$ pdm install
```

> [!TIP]
> If you don't have PDM installed, you can create a virtual environment with `venv` and install dependencies with `pip install -r requirements.txt`.

To initialize the app, run the `flask init-app` command:

```
$ pdm run flask init-app
```

If you just want to try it out, generate fake data with `flask lorem` command then run the app:

```
$ pdm run flask lorem
```

It will create a test account:

* email: `admin@helloflask.com`
* password: `moments`

Now you can run the app:

```
$ pdm run flask run
* Running on http://127.0.0.1:5000/
```
Usage
Once the application is running, follow these steps:

* Upload an Image:
Go to the homepage and upload an image. The image will be processed, and alternative text (caption) will be automatically generated.

* View Generated Caption and Tags:
After uploading the image, the caption generated by the Azure Vision API will be displayed on the image as an alt text. You can also search for images using keywords that are matched to tags generated for the images.

* Search for Images:
You can use the search feature to find images by entering keywords. The application will match these keywords with the tags associated with images.

Changes:
- [x] Created an azure_vision.py file that contains functions that interact with the Azure Vision API to generate captions (alternative text) and tags for images uploaded by users. These functions use Azure's Computer Vision API to analyze the images and retrieve textual information that describes the image content.
- [x] We have made the changes in the following functions:

* generate_caption: This function sends an image to the Azure Vision API to generate a description (caption) for the image, which is returned as the alt text for accessibility.

* generate_tags: This function sends an image to the Azure Vision API to generate tags based on the image's content and returns a list of these tags.

* upload: This function handles the image upload process, generates captions and tags using Azure Vision API, saves the image and metadata (caption, tags) to the database, and then redirects the user to the photo view page.

Environment Variables
The application requires two environment variables:

VISION_ENDPOINT: The endpoint for the Azure Vision API.
VISION_KEY: The subscription key for accessing the Azure Vision API.
- [x] These variables have been added to the .env file, as mentioned in the Installation section.

Features
Alternative Text Generation
Machine Learning Model: The application uses Azure's Vision API to generate captions (alternative text) for images.
How It Works: When a user uploads an image, the application sends it to the Azure API, which processes the image and returns a description (caption). This caption is then displayed as the alt attribute for the image in HTML.
Image Search
Machine Learning Model: The application uses Azure's Vision API to analyze the content of images and generate tags.
How It Works: When a user uploads an image, the application sends it to the Azure API, which returns a list of tags based on the image's content. The tags are stored in the database and used for searching images based on keywords.
## License

This project is licensed under the MIT License (see the
[LICENSE](LICENSE) file for details).
